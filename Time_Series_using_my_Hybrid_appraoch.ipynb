{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOiXC9FS4wXYp+aweOygvZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zabihullahburhani/-Improving-the-Accuracy-of-Crude-Oil-Price-Prediction-Using-a-Transformer-Based-Hybrid-Approach/blob/main/Time_Series_using_my_Hybrid_appraoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1️⃣ تعریف مدل ترکیبی LSTM و Transformer\n",
        "class LSTMTransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, lstm_hidden_dim, d_model, n_heads, num_layers, seq_len, dropout=0.1):\n",
        "        super(LSTMTransformerModel, self).__init__()\n",
        "\n",
        "        # لایه LSTM\n",
        "        self.lstm = nn.LSTM(input_dim, lstm_hidden_dim, num_layers=1, batch_first=True)\n",
        "\n",
        "        # پروجکشن برای تبدیل خروجی LSTM به ابعاد d_model\n",
        "        self.lstm_projection = nn.Linear(lstm_hidden_dim, d_model)\n",
        "\n",
        "        # لایه‌های Transformer\n",
        "        transformer_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(transformer_layer, num_layers=num_layers)\n",
        "\n",
        "        # لایه خروجی\n",
        "        self.fc = nn.Linear(d_model, input_dim)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        # عبور از LSTM\n",
        "        lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, lstm_hidden_dim)\n",
        "\n",
        "        # پروجکشن به ابعاد d_model\n",
        "        transformer_in = self.lstm_projection(lstm_out)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # عبور از Transformer\n",
        "        transformer_out = self.transformer(transformer_in)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # پیش‌بینی با استفاده از لایه خطی\n",
        "        out = self.fc(transformer_out[:, -1, :])  # فقط از آخرین timestep استفاده می‌کنیم\n",
        "        return out\n",
        "\n",
        "# 2️⃣ بارگذاری داده‌ها\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "\n",
        "# 3️⃣ پیش‌پردازش داده‌ها\n",
        "def preprocess_data(data, seq_len=60, train_ratio=0.8):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "\n",
        "    train_size = int(len(X) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "# 4️⃣ آموزش و اعتبارسنجی مدل\n",
        "def train_evaluate_model(X, y, k=10, epochs=20, lr=0.001, model_path=\"lstm_transformer_model.pth\"):\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "\n",
        "    best_model = None\n",
        "    best_mse = float('inf')\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "\n",
        "        train_x, val_x = torch.tensor(X[train_idx], dtype=torch.float32), torch.tensor(X[val_idx], dtype=torch.float32)\n",
        "        train_y, val_y = torch.tensor(y[train_idx], dtype=torch.float32), torch.tensor(y[val_idx], dtype=torch.float32)\n",
        "\n",
        "        model = LSTMTransformerModel(\n",
        "            input_dim=1,\n",
        "            lstm_hidden_dim=64,\n",
        "            d_model=64,\n",
        "            n_heads=8,\n",
        "            num_layers=2,\n",
        "            seq_len=60\n",
        "        )\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(train_x)\n",
        "            loss = criterion(predictions.squeeze(), train_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(val_x).detach().numpy()\n",
        "            val_actual = val_y.numpy()\n",
        "\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# 5️⃣ پیش‌بینی و مقایسه\n",
        "def predict_and_compare(model, X_train, y_train, X_test, y_test, scaler, prediction_steps=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions = model(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    test_actual = y_test\n",
        "\n",
        "    test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
        "    test_actual = scaler.inverse_transform(test_actual.reshape(-1, 1))\n",
        "\n",
        "    future_predictions = []\n",
        "    current_input = torch.tensor(X_test[-1], dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    for _ in range(prediction_steps):\n",
        "        with torch.no_grad():\n",
        "            prediction = model(current_input).detach().numpy()\n",
        "        future_predictions.append(prediction[0, 0])\n",
        "\n",
        "        new_input = np.roll(current_input.numpy(), -1, axis=1)\n",
        "        new_input[0, -1] = prediction\n",
        "        current_input = torch.tensor(new_input, dtype=torch.float32)\n",
        "\n",
        "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(range(len(test_actual)), test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(range(len(test_predictions)), test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(range(len(test_actual), len(test_actual) + prediction_steps), future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Time Series Price Forecast and Comparison\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "\n",
        "    return future_predictions\n",
        "\n",
        "# 6️⃣ اجرای فرآیند\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "X_train, y_train, X_test, y_test, scaler = preprocess_data(data)\n",
        "\n",
        "model = train_evaluate_model(X_train, y_train)\n",
        "future_predictions = predict_and_compare(model, X_train, y_train, X_test, y_test, scaler)"
      ],
      "metadata": {
        "id": "mIG4BEafJpVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "above mode LSTM + Transformer"
      ],
      "metadata": {
        "id": "o35_UxBXjc8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1️⃣ تعریف مدل ترکیبی CNN و Transformer\n",
        "class CNNTransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, cnn_channels, d_model, n_heads, num_layers, seq_len, dropout=0.1):\n",
        "        super(CNNTransformerModel, self).__init__()\n",
        "\n",
        "        # لایه CNN\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=input_dim, out_channels=cnn_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(in_channels=cnn_channels, out_channels=cnn_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # پروجکشن برای تبدیل خروجی CNN به ابعاد d_model\n",
        "        self.cnn_projection = nn.Linear(cnn_channels, d_model)\n",
        "\n",
        "        # لایه‌های Transformer\n",
        "        transformer_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(transformer_layer, num_layers=num_layers)\n",
        "\n",
        "        # لایه خروجی\n",
        "        self.fc = nn.Linear(d_model, input_dim)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        # تغییر ابعاد برای CNN: (batch_size, input_dim, seq_len)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # عبور از CNN\n",
        "        cnn_out = self.cnn(x)  # (batch_size, cnn_channels, seq_len)\n",
        "        cnn_out = cnn_out.permute(0, 2, 1)  # (batch_size, seq_len, cnn_channels)\n",
        "\n",
        "        # پروجکشن به ابعاد d_model\n",
        "        transformer_in = self.cnn_projection(cnn_out)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # عبور از Transformer\n",
        "        transformer_out = self.transformer(transformer_in)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # پیش‌بینی با استفاده از لایه خطی\n",
        "        out = self.fc(transformer_out[:, -1, :])  # فقط از آخرین timestep استفاده می‌کنیم\n",
        "        return out\n",
        "\n",
        "# 2️⃣ بارگذاری داده‌ها\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "\n",
        "# 3️⃣ پیش‌پردازش داده‌ها\n",
        "def preprocess_data(data, seq_len=60, train_ratio=0.8):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "\n",
        "    train_size = int(len(X) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "# 4️⃣ آموزش و اعتبارسنجی مدل\n",
        "def train_evaluate_model(X, y, k=10, epochs=20, lr=0.001, model_path=\"cnn_transformer_model.pth\"):\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "\n",
        "    best_model = None\n",
        "    best_mse = float('inf')\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "\n",
        "        train_x, val_x = torch.tensor(X[train_idx], dtype=torch.float32), torch.tensor(X[val_idx], dtype=torch.float32)\n",
        "        train_y, val_y = torch.tensor(y[train_idx], dtype=torch.float32), torch.tensor(y[val_idx], dtype=torch.float32)\n",
        "\n",
        "        model = CNNTransformerModel(\n",
        "            input_dim=1,\n",
        "            cnn_channels=64,\n",
        "            d_model=64,\n",
        "            n_heads=8,\n",
        "            num_layers=2,\n",
        "            seq_len=60\n",
        "        )\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(train_x)\n",
        "            loss = criterion(predictions.squeeze(), train_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(val_x).detach().numpy()\n",
        "            val_actual = val_y.numpy()\n",
        "\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# 5️⃣ پیش‌بینی و مقایسه\n",
        "def predict_and_compare(model, X_train, y_train, X_test, y_test, scaler, prediction_steps=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions = model(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    test_actual = y_test\n",
        "\n",
        "    test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
        "    test_actual = scaler.inverse_transform(test_actual.reshape(-1, 1))\n",
        "\n",
        "    future_predictions = []\n",
        "    current_input = torch.tensor(X_test[-1], dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    for _ in range(prediction_steps):\n",
        "        with torch.no_grad():\n",
        "            prediction = model(current_input).detach().numpy()\n",
        "        future_predictions.append(prediction[0, 0])\n",
        "\n",
        "        new_input = np.roll(current_input.numpy(), -1, axis=1)\n",
        "        new_input[0, -1] = prediction\n",
        "        current_input = torch.tensor(new_input, dtype=torch.float32)\n",
        "\n",
        "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(range(len(test_actual)), test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(range(len(test_predictions)), test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(range(len(test_actual), len(test_actual) + prediction_steps), future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast and Comparison (CNN + Transformer)\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "\n",
        "    return future_predictions\n",
        "\n",
        "# 6️⃣ اجرای فرآیند\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "X_train, y_train, X_test, y_test, scaler = preprocess_data(data)\n",
        "\n",
        "model = train_evaluate_model(X_train, y_train)\n",
        "future_predictions = predict_and_compare(model, X_train, y_train, X_test, y_test, scaler)"
      ],
      "metadata": {
        "id": "9UtEG9UWjexF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code: cnn+transformer"
      ],
      "metadata": {
        "id": "sZwm5QpZnhXo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fX3NPCUsnnQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1️⃣ تعریف مدل ترکیبی GRU و Attention\n",
        "class GRUAttentionModel(nn.Module):\n",
        "    def __init__(self, input_dim, gru_hidden_dim, seq_len, dropout=0.1):\n",
        "        super(GRUAttentionModel, self).__init__()\n",
        "\n",
        "        # لایه GRU\n",
        "        self.gru = nn.GRU(input_dim, gru_hidden_dim, num_layers=1, batch_first=True)\n",
        "\n",
        "        # مکانیزم توجه (Attention)\n",
        "        self.attention = nn.Linear(gru_hidden_dim * 2, seq_len)  # برای محاسبه وزن‌های توجه\n",
        "        self.context_vector = nn.Linear(gru_hidden_dim, gru_hidden_dim)  # برای تولید بردار زمینه\n",
        "\n",
        "        # لایه خروجی\n",
        "        self.fc = nn.Linear(gru_hidden_dim, input_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        # عبور از GRU\n",
        "        gru_out, _ = self.gru(x)  # (batch_size, seq_len, gru_hidden_dim)\n",
        "        gru_out = self.dropout(gru_out)\n",
        "\n",
        "        # محاسبه وزن‌های توجه\n",
        "        last_hidden = gru_out[:, -1, :]  # (batch_size, gru_hidden_dim)\n",
        "        last_hidden_expanded = last_hidden.unsqueeze(1).repeat(1, self.seq_len, 1)  # (batch_size, seq_len, gru_hidden_dim)\n",
        "        attention_input = torch.cat((gru_out, last_hidden_expanded), dim=2)  # (batch_size, seq_len, gru_hidden_dim * 2)\n",
        "        attention_weights = torch.softmax(self.attention(attention_input), dim=1)  # (batch_size, seq_len, seq_len)\n",
        "\n",
        "        # محاسبه بردار زمینه (Context Vector)\n",
        "        context = torch.bmm(attention_weights.transpose(1, 2), gru_out)  # (batch_size, seq_len, gru_hidden_dim)\n",
        "        context = self.context_vector(context[:, -1, :])  # (batch_size, gru_hidden_dim)\n",
        "\n",
        "        # پیش‌بینی با استفاده از لایه خطی\n",
        "        out = self.fc(context)  # (batch_size, input_dim)\n",
        "        return out\n",
        "\n",
        "# 2️⃣ بارگذاری داده‌ها\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "\n",
        "# 3️⃣ پیش‌پردازش داده‌ها\n",
        "def preprocess_data(data, seq_len=60, train_ratio=0.8):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "\n",
        "    train_size = int(len(X) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "# 4️⃣ آموزش و اعتبارسنجی مدل\n",
        "def train_evaluate_model(X, y, k=10, epochs=20, lr=0.001, model_path=\"gru_attention_model.pth\"):\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "\n",
        "    best_model = None\n",
        "    best_mse = float('inf')\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "\n",
        "        train_x, val_x = torch.tensor(X[train_idx], dtype=torch.float32), torch.tensor(X[val_idx], dtype=torch.float32)\n",
        "        train_y, val_y = torch.tensor(y[train_idx], dtype=torch.float32), torch.tensor(y[val_idx], dtype=torch.float32)\n",
        "\n",
        "        model = GRUAttentionModel(\n",
        "            input_dim=1,\n",
        "            gru_hidden_dim=64,\n",
        "            seq_len=60\n",
        "        )\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(train_x)\n",
        "            loss = criterion(predictions.squeeze(), train_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(val_x).detach().numpy()\n",
        "            val_actual = val_y.numpy()\n",
        "\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# 5️⃣ پیش‌بینی و مقایسه\n",
        "def predict_and_compare(model, X_train, y_train, X_test, y_test, scaler, prediction_steps=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions = model(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    test_actual = y_test\n",
        "\n",
        "    test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
        "    test_actual = scaler.inverse_transform(test_actual.reshape(-1, 1))\n",
        "\n",
        "    future_predictions = []\n",
        "    current_input = torch.tensor(X_test[-1], dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    for _ in range(prediction_steps):\n",
        "        with torch.no_grad():\n",
        "            prediction = model(current_input).detach().numpy()\n",
        "        future_predictions.append(prediction[0, 0])\n",
        "\n",
        "        new_input = np.roll(current_input.numpy(), -1, axis=1)\n",
        "        new_input[0, -1] = prediction\n",
        "        current_input = torch.tensor(new_input, dtype=torch.float32)\n",
        "\n",
        "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(range(len(test_actual)), test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(range(len(test_predictions)), test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(range(len(test_actual), len(test_actual) + prediction_steps), future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast and Comparison (GRU + Attention)\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "\n",
        "    return future_predictions\n",
        "\n",
        "# 6️⃣ اجرای فرآیند\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "X_train, y_train, X_test, y_test, scaler = preprocess_data(data)\n",
        "\n",
        "model = train_evaluate_model(X_train, y_train)\n",
        "future_predictions = predict_and_compare(model, X_train, y_train, X_test, y_test, scaler)"
      ],
      "metadata": {
        "id": "rZgtc7aZpAhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1️⃣ تعریف مدل ترکیبی GRU و Transformer\n",
        "class GRUTransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, gru_hidden_dim, d_model, n_heads, num_layers, seq_len, dropout=0.1):\n",
        "        super(GRUTransformerModel, self).__init__()\n",
        "\n",
        "        # لایه GRU\n",
        "        self.gru = nn.GRU(input_dim, gru_hidden_dim, num_layers=1, batch_first=True)\n",
        "\n",
        "        # پروجکشن برای تبدیل خروجی GRU به ابعاد d_model\n",
        "        self.gru_projection = nn.Linear(gru_hidden_dim, d_model)\n",
        "\n",
        "        # لایه‌های Transformer\n",
        "        transformer_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(transformer_layer, num_layers=num_layers)\n",
        "\n",
        "        # لایه خروجی\n",
        "        self.fc = nn.Linear(d_model, input_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        # عبور از GRU\n",
        "        gru_out, _ = self.gru(x)  # (batch_size, seq_len, gru_hidden_dim)\n",
        "        gru_out = self.dropout(gru_out)\n",
        "\n",
        "        # پروجکشن به ابعاد d_model\n",
        "        transformer_in = self.gru_projection(gru_out)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # عبور از Transformer\n",
        "        transformer_out = self.transformer(transformer_in)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # پیش‌بینی با استفاده از لایه خطی\n",
        "        out = self.fc(transformer_out[:, -1, :])  # فقط از آخرین timestep استفاده می‌کنیم\n",
        "        return out\n",
        "\n",
        "# 2️⃣ بارگذاری داده‌ها\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "\n",
        "# 3️⃣ پیش‌پردازش داده‌ها\n",
        "def preprocess_data(data, seq_len=60, train_ratio=0.8):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "\n",
        "    train_size = int(len(X) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "# 4️⃣ آموزش و اعتبارسنجی مدل\n",
        "def train_evaluate_model(X, y, k=10, epochs=20, lr=0.001, model_path=\"gru_transformer_model.pth\"):\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "\n",
        "    best_model = None\n",
        "    best_mse = float('inf')\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "\n",
        "        train_x, val_x = torch.tensor(X[train_idx], dtype=torch.float32), torch.tensor(X[val_idx], dtype=torch.float32)\n",
        "        train_y, val_y = torch.tensor(y[train_idx], dtype=torch.float32), torch.tensor(y[val_idx], dtype=torch.float32)\n",
        "\n",
        "        model = GRUTransformerModel(\n",
        "            input_dim=1,\n",
        "            gru_hidden_dim=64,\n",
        "            d_model=64,\n",
        "            n_heads=8,\n",
        "            num_layers=2,\n",
        "            seq_len=60\n",
        "        )\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(train_x)\n",
        "            loss = criterion(predictions.squeeze(), train_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(val_x).detach().numpy()\n",
        "            val_actual = val_y.numpy()\n",
        "\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# 5️⃣ پیش‌بینی و مقایسه\n",
        "def predict_and_compare(model, X_train, y_train, X_test, y_test, scaler, prediction_steps=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions = model(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    test_actual = y_test\n",
        "\n",
        "    test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
        "    test_actual = scaler.inverse_transform(test_actual.reshape(-1, 1))\n",
        "\n",
        "    future_predictions = []\n",
        "    current_input = torch.tensor(X_test[-1], dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    for _ in range(prediction_steps):\n",
        "        with torch.no_grad():\n",
        "            prediction = model(current_input).detach().numpy()\n",
        "        future_predictions.append(prediction[0, 0])\n",
        "\n",
        "        new_input = np.roll(current_input.numpy(), -1, axis=1)\n",
        "        new_input[0, -1] = prediction\n",
        "        current_input = torch.tensor(new_input, dtype=torch.float32)\n",
        "\n",
        "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(range(len(test_actual)), test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(range(len(test_predictions)), test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(range(len(test_actual), len(test_actual) + prediction_steps), future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast and Comparison (GRU + Transformer)\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "\n",
        "    return future_predictions\n",
        "\n",
        "# 6️⃣ اجرای فرآیند\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "X_train, y_train, X_test, y_test, scaler = preprocess_data(data)\n",
        "\n",
        "model = train_evaluate_model(X_train, y_train)\n",
        "future_predictions = predict_and_compare(model, X_train, y_train, X_test, y_test, scaler)"
      ],
      "metadata": {
        "id": "h9RUtn6HpJPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, seq_len):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, input_dim)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        gru_out, _ = self.gru(x)\n",
        "        out = self.fc(gru_out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "\n",
        "def preprocess_data(data, seq_len=60, train_ratio=0.8):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    train_size = int(len(X) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "    return X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "def train_evaluate_model(X, y, k=10, epochs=20, lr=0.001, model_path=\"gru_model.pth\"):\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_x, val_x = torch.tensor(X[train_idx], dtype=torch.float32), torch.tensor(X[val_idx], dtype=torch.float32)\n",
        "        train_y, val_y = torch.tensor(y[train_idx], dtype=torch.float32), torch.tensor(y[val_idx], dtype=torch.float32)\n",
        "        model = GRUModel(input_dim=1, hidden_dim=64, seq_len=60)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(train_x)\n",
        "            loss = criterion(predictions.squeeze(), train_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(val_x).detach().numpy()\n",
        "            val_actual = val_y.numpy()\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, X_test, y_test, scaler, prediction_steps=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions = model(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "    test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
        "    future_predictions = []\n",
        "    current_input = torch.tensor(X_test[-1], dtype=torch.float32).unsqueeze(0)\n",
        "    for _ in range(prediction_steps):\n",
        "        with torch.no_grad():\n",
        "            prediction = model(current_input).detach().numpy()\n",
        "        future_predictions.append(prediction[0, 0])\n",
        "        new_input = np.roll(current_input.numpy(), -1, axis=1)\n",
        "        new_input[0, -1] = prediction\n",
        "        current_input = torch.tensor(new_input, dtype=torch.float32)\n",
        "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(range(len(test_actual)), test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(range(len(test_predictions)), test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(range(len(test_actual), len(test_actual) + prediction_steps), future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (GRU)\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "X_train, y_train, X_test, y_test, scaler = preprocess_data(data)\n",
        "model = train_evaluate_model(X_train, y_train)\n",
        "future_predictions = predict_and_compare(model, X_test, y_test, scaler)"
      ],
      "metadata": {
        "id": "Oavqh3LC8HTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, seq_len):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, input_dim)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "\n",
        "def preprocess_data(data, seq_len=60, train_ratio=0.8):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    train_size = int(len(X) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "    return X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "def train_evaluate_model(X, y, k=10, epochs=20, lr=0.001, model_path=\"lstm_model.pth\"):\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_x, val_x = torch.tensor(X[train_idx], dtype=torch.float32), torch.tensor(X[val_idx], dtype=torch.float32)\n",
        "        train_y, val_y = torch.tensor(y[train_idx], dtype=torch.float32), torch.tensor(y[val_idx], dtype=torch.float32)\n",
        "        model = LSTMModel(input_dim=1, hidden_dim=64, seq_len=60)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(train_x)\n",
        "            loss = criterion(predictions.squeeze(), train_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(val_x).detach().numpy()\n",
        "            val_actual = val_y.numpy()\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, X_test, y_test, scaler, prediction_steps=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions = model(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "    test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
        "    future_predictions = []\n",
        "    current_input = torch.tensor(X_test[-1], dtype=torch.float32).unsqueeze(0)\n",
        "    for _ in range(prediction_steps):\n",
        "        with torch.no_grad():\n",
        "            prediction = model(current_input).detach().numpy()\n",
        "        future_predictions.append(prediction[0, 0])\n",
        "        new_input = np.roll(current_input.numpy(), -1, axis=1)\n",
        "        new_input[0, -1] = prediction\n",
        "        current_input = torch.tensor(new_input, dtype=torch.float32)\n",
        "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(range(len(test_actual)), test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(range(len(test_predictions)), test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(range(len(test_actual), len(test_actual) + prediction_steps), future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (LSTM)\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "X_train, y_train, X_test, y_test, scaler = preprocess_data(data)\n",
        "model = train_evaluate_model(X_train, y_train)\n",
        "future_predictions = predict_and_compare(model, X_test, y_test, scaler)"
      ],
      "metadata": {
        "id": "OZocsxFP8JLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_heads, num_layers, seq_len):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, seq_len, d_model))\n",
        "        transformer_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=d_model*4, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(transformer_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(d_model, input_dim)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_projection(x) + self.positional_encoding\n",
        "        x = self.transformer(x)\n",
        "        out = self.fc(x[:, -1, :])\n",
        "        return out\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "\n",
        "def preprocess_data(data, seq_len=60, train_ratio=0.8):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    train_size = int(len(X) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "    return X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "def train_evaluate_model(X, y, k=10, epochs=20, lr=0.001, model_path=\"transformer_model.pth\"):\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_x, val_x = torch.tensor(X[train_idx], dtype=torch.float32), torch.tensor(X[val_idx], dtype=torch.float32)\n",
        "        train_y, val_y = torch.tensor(y[train_idx], dtype=torch.float32), torch.tensor(y[val_idx], dtype=torch.float32)\n",
        "        model = TransformerModel(input_dim=1, d_model=64, n_heads=8, num_layers=2, seq_len=60)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(train_x)\n",
        "            loss = criterion(predictions.squeeze(), train_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(val_x).detach().numpy()\n",
        "            val_actual = val_y.numpy()\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, X_test, y_test, scaler, prediction_steps=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions = model(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "    test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
        "    future_predictions = []\n",
        "    current_input = torch.tensor(X_test[-1], dtype=torch.float32).unsqueeze(0)\n",
        "    for _ in range(prediction_steps):\n",
        "        with torch.no_grad():\n",
        "            prediction = model(current_input).detach().numpy()\n",
        "        future_predictions.append(prediction[0, 0])\n",
        "        new_input = np.roll(current_input.numpy(), -1, axis=1)\n",
        "        new_input[0, -1] = prediction\n",
        "        current_input = torch.tensor(new_input, dtype=torch.float32)\n",
        "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(range(len(test_actual)), test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(range(len(test_predictions)), test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(range(len(test_actual), len(test_actual) + prediction_steps), future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (Transformer)\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "X_train, y_train, X_test, y_test, scaler = preprocess_data(data)\n",
        "model = train_evaluate_model(X_train, y_train)\n",
        "future_predictions = predict_and_compare(model, X_test, y_test, scaler)"
      ],
      "metadata": {
        "id": "lHnE1STB8Q5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "class ProbSparseAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, factor=5):\n",
        "        super(ProbSparseAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "        self.factor = factor\n",
        "        self.query_projection = nn.Linear(d_model, d_model)\n",
        "        self.key_projection = nn.Linear(d_model, d_model)\n",
        "        self.value_projection = nn.Linear(d_model, d_model)\n",
        "        self.out_projection = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        batch_size, seq_len, _ = Q.size()\n",
        "        Q = self.query_projection(Q).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.key_projection(K).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.value_projection(V).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        _, indices = scores.topk(self.factor, dim=-1)\n",
        "        sparse_scores = torch.zeros_like(scores).scatter_(-1, indices, scores)\n",
        "        attn = torch.softmax(sparse_scores, dim=-1)\n",
        "        out = torch.matmul(attn, V)\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "        return self.out_projection(out)\n",
        "\n",
        "class Informer(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_heads, num_layers, seq_len, pred_len):\n",
        "        super(Informer, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, max(seq_len, pred_len), d_model))\n",
        "        self.encoder_layers = nn.ModuleList([nn.ModuleList([ProbSparseAttention(d_model, n_heads), nn.LayerNorm(d_model), nn.Linear(d_model, d_model*4), nn.ReLU(), nn.Linear(d_model*4, d_model), nn.LayerNorm(d_model)]) for _ in range(num_layers)])\n",
        "        self.decoder_projection = nn.Linear(input_dim, d_model)\n",
        "        self.decoder_layers = nn.ModuleList([nn.ModuleList([ProbSparseAttention(d_model, n_heads), nn.LayerNorm(d_model), ProbSparseAttention(d_model, n_heads), nn.LayerNorm(d_model), nn.Linear(d_model, d_model*4), nn.ReLU(), nn.Linear(d_model*4, d_model), nn.LayerNorm(d_model)]) for _ in range(num_layers)])\n",
        "        self.output_projection = nn.Linear(d_model, input_dim)\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "\n",
        "    def forward(self, x_enc, x_dec):\n",
        "        enc_input = self.input_projection(x_enc) + self.positional_encoding[:, :x_enc.size(1), :]\n",
        "        for attn, norm1, ff1, relu, ff2, norm2 in self.encoder_layers:\n",
        "            attn_output = attn(enc_input, enc_input, enc_input)\n",
        "            enc_input = norm1(enc_input + attn_output)\n",
        "            ff_output = ff2(relu(ff1(enc_input)))\n",
        "            enc_input = norm2(enc_input + ff_output)\n",
        "        dec_input = self.decoder_projection(x_dec) + self.positional_encoding[:, :x_dec.size(1), :]\n",
        "        for attn1, norm1, attn2, norm2, ff1, relu, ff2, norm3 in self.decoder_layers:\n",
        "            dec_input = norm1(dec_input + attn1(dec_input, dec_input, dec_input))\n",
        "            dec_input = norm2(dec_input + attn2(dec_input, enc_input, enc_input))\n",
        "            ff_output = ff2(relu(ff1(dec_input)))\n",
        "            dec_input = norm3(dec_input + ff_output)\n",
        "        output = self.output_projection(dec_input[:, -self.pred_len:, :])\n",
        "        return output\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "\n",
        "def preprocess_data(data, seq_len=60, train_ratio=0.8):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    train_size = int(len(X) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "    return X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "def train_evaluate_model(X, y, k=10, epochs=20, lr=0.001, model_path=\"informer_model.pth\"):\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_x, val_x = torch.tensor(X[train_idx], dtype=torch.float32), torch.tensor(X[val_idx], dtype=torch.float32)\n",
        "        train_y, val_y = torch.tensor(y[train_idx], dtype=torch.float32), torch.tensor(y[val_idx], dtype=torch.float32)\n",
        "        model = Informer(input_dim=1, d_model=64, n_heads=8, num_layers=2, seq_len=60, pred_len=1)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(train_x, train_x)\n",
        "            loss = criterion(predictions.squeeze(), train_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(val_x, val_x).detach().numpy()\n",
        "            val_actual = val_y.numpy()\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, X_test, y_test, scaler, prediction_steps=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions = model(torch.tensor(X_test, dtype=torch.float32), torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "    test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
        "    future_predictions = []\n",
        "    current_input = torch.tensor(X_test[-1], dtype=torch.float32).unsqueeze(0)\n",
        "    for _ in range(prediction_steps):\n",
        "        with torch.no_grad():\n",
        "            prediction = model(current_input, current_input).detach().numpy()\n",
        "        future_predictions.append(prediction[0, 0])\n",
        "        new_input = np.roll(current_input.numpy(), -1, axis=1)\n",
        "        new_input[0, -1] = prediction\n",
        "        current_input = torch.tensor(new_input, dtype=torch.float32)\n",
        "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(range(len(test_actual)), test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(range(len(test_predictions)), test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(range(len(test_actual), len(test_actual) + prediction_steps), future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (Informer)\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "X_train, y_train, X_test, y_test, scaler = preprocess_data(data)\n",
        "model = train_evaluate_model(X_train, y_train)\n",
        "future_predictions = predict_and_compare(model, X_test, y_test, scaler)"
      ],
      "metadata": {
        "id": "_RJvwL5u8WE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class AutoCorrelation(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, factor=5):\n",
        "        super(AutoCorrelation, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "        self.factor = factor\n",
        "        self.query_projection = nn.Linear(d_model, d_model)\n",
        "        self.key_projection = nn.Linear(d_model, d_model)\n",
        "        self.value_projection = nn.Linear(d_model, d_model)\n",
        "        self.out_projection = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        batch_size, seq_len, _ = Q.size()\n",
        "        Q = self.query_projection(Q).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.key_projection(K).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.value_projection(V).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        Q_fft = torch.fft.rfft(Q, dim=2)\n",
        "        K_fft = torch.fft.rfft(K, dim=2)\n",
        "        scores = torch.fft.irfft(Q_fft * torch.conj(K_fft), dim=2, n=seq_len)\n",
        "        _, indices = scores.topk(self.factor, dim=-1)\n",
        "        sparse_scores = torch.zeros_like(scores).scatter_(-1, indices, scores)\n",
        "        attn = torch.softmax(sparse_scores, dim=-1)\n",
        "        out = torch.matmul(attn, V)\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "        return self.out_projection(out)\n",
        "\n",
        "class SeriesDecomposition(nn.Module):\n",
        "    def __init__(self, kernel_size=25):\n",
        "        super(SeriesDecomposition, self).__init__()\n",
        "        self.avg_pool = nn.AvgPool1d(kernel_size, stride=1, padding=kernel_size//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        trend = self.avg_pool(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
        "        seasonal = x - trend\n",
        "        return trend, seasonal\n",
        "\n",
        "class Autoformer(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_heads, num_layers, seq_len, pred_len):\n",
        "        super(Autoformer, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "        self.decomposition = SeriesDecomposition()\n",
        "        self.encoder_layers = nn.ModuleList([nn.ModuleList([AutoCorrelation(d_model, n_heads), nn.LayerNorm(d_model), nn.Linear(d_model, d_model*4), nn.ReLU(), nn.Linear(d_model*4, d_model), nn.LayerNorm(d_model)]) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([nn.ModuleList([AutoCorrelation(d_model, n_heads), nn.LayerNorm(d_model), AutoCorrelation(d_model, n_heads), nn.LayerNorm(d_model), nn.Linear(d_model, d_model*4), nn.ReLU(), nn.Linear(d_model*4, d_model), nn.LayerNorm(d_model)]) for _ in range(num_layers)])\n",
        "        self.output_projection = nn.Linear(d_model, input_dim)\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "\n",
        "    def forward(self, x_enc, x_dec):\n",
        "        trend, seasonal = self.decomposition(x_enc)\n",
        "        enc_input = self.input_projection(seasonal)\n",
        "        for attn, norm1, ff1, relu, ff2, norm2 in self.encoder_layers:\n",
        "            attn_output = attn(enc_input, enc_input, enc_input)\n",
        "            enc_input = norm1(enc_input + attn_output)\n",
        "            ff_output = ff2(relu(ff1(enc_input)))\n",
        "            enc_input = norm2(enc_input + ff_output)\n",
        "        dec_input = self.input_projection(x_dec)\n",
        "        for attn1, norm1, attn2, norm2, ff1, relu, ff2, norm3 in self.decoder_layers:\n",
        "            dec_input = norm1(dec_input + attn1(dec_input, dec_input, dec_input))\n",
        "            dec_input = norm2(dec_input + attn2(dec_input, enc_input, enc_input))\n",
        "            ff_output = ff2(relu(ff1(dec_input)))\n",
        "            dec_input = norm3(dec_input + ff_output)\n",
        "        output = self.output_projection(dec_input[:, -self.pred_len:, :]) + trend[:, -self.pred_len:, :]\n",
        "        return output\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "\n",
        "def preprocess_data(data, seq_len=60, train_ratio=0.8):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    train_size = int(len(X) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "    return X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "def train_evaluate_model(X, y, k=10, epochs=20, lr=0.001, model_path=\"autoformer_model.pth\"):\n",
        "    kf = KFold(n_splits=k, shuffle=True)\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_x, val_x = torch.tensor(X[train_idx], dtype=torch.float32), torch.tensor(X[val_idx], dtype=torch.float32)\n",
        "        train_y, val_y = torch.tensor(y[train_idx], dtype=torch.float32), torch.tensor(y[val_idx], dtype=torch.float32)\n",
        "        model = Autoformer(input_dim=1, d_model=64, n_heads=8, num_layers=2, seq_len=60, pred_len=1)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(train_x, train_x)\n",
        "            loss = criterion(predictions.squeeze(), train_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(val_x, val_x).detach().numpy()\n",
        "            val_actual = val_y.numpy()\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, X_test, y_test, scaler, prediction_steps=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_predictions = model(torch.tensor(X_test, dtype=torch.float32), torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "    test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
        "    future_predictions = []\n",
        "    current_input = torch.tensor(X_test[-1], dtype=torch.float32).unsqueeze(0)\n",
        "    for _ in range(prediction_steps):\n",
        "        with torch.no_grad():\n",
        "            prediction = model(current_input, current_input).detach().numpy()\n",
        "        future_predictions.append(prediction[0, 0])\n",
        "        new_input = np.roll(current_input.numpy(), -1, axis=1)\n",
        "        new_input[0, -1] = prediction\n",
        "        current_input = torch.tensor(new_input, dtype=torch.float32)\n",
        "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(range(len(test_actual)), test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(range(len(test_predictions)), test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(range(len(test_actual), len(test_actual) + prediction_steps), future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (Autoformer)\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "X_train, y_train, X_test, y_test, scaler = preprocess_data(data)\n",
        "model = train_evaluate_model(X_train, y_train)\n",
        "future_predictions = predict_and_compare(model, X_test, y_test, scaler)"
      ],
      "metadata": {
        "id": "AeaJKIUT8gQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data = data.rename(columns={'Date': 'ds', 'Close': 'y'})\n",
        "    return data\n",
        "\n",
        "def train_evaluate_model(data, k=10):\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    kf = KFold(n_splits=k, shuffle=False)  # shuffle=False برای حفظ ترتیب زمانی\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_data, val_data = data.iloc[train_idx], data.iloc[val_idx]\n",
        "        model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)\n",
        "        model.fit(train_data)\n",
        "        future_dates = model.make_future_dataframe(periods=30)\n",
        "        forecast = model.predict(future_dates)\n",
        "        val_predictions = forecast.tail(len(val_data))['yhat'].values\n",
        "        val_actual = val_data['y'].values\n",
        "        mse = mean_squared_error(val_actual, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_actual, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, data, prediction_steps=30):\n",
        "    future_dates = model.make_future_dataframe(periods=prediction_steps)\n",
        "    forecast = model.predict(future_dates)\n",
        "    test_data = data.tail(len(forecast) - prediction_steps)\n",
        "    test_actual = test_data['y'].values\n",
        "    test_predictions = forecast.tail(len(test_data))['yhat'].values\n",
        "    future_predictions = forecast.tail(prediction_steps)['yhat'].values\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(test_data.index, test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(test_data.index, test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    plt.plot(forecast.tail(prediction_steps).index, future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (Prophet)\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "model = train_evaluate_model(data)\n",
        "future_predictions = predict_and_compare(model, data)"
      ],
      "metadata": {
        "id": "ADeBQeo-8iNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data['Close']\n",
        "\n",
        "def train_evaluate_model(data, k=10, order=(5,1,0)):\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    kf = KFold(n_splits=k, shuffle=False)\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_data, val_data = data.iloc[train_idx], data.iloc[val_idx]\n",
        "        model = ARIMA(train_data, order=order)\n",
        "        model_fit = model.fit()\n",
        "        val_predictions = model_fit.forecast(steps=len(val_data))\n",
        "        mse = mean_squared_error(val_data, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_data, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model_fit\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, data, prediction_steps=30):\n",
        "    test_actual = data.tail(len(data) - len(model.arima_resid)).values\n",
        "    test_predictions = model.forecast(steps=len(test_actual))\n",
        "    future_predictions = model.forecast(steps=prediction_steps)\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(data.index[-len(test_actual):], test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(data.index[-len(test_actual):], test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    future_dates = pd.date_range(start=data.index[-1], periods=prediction_steps + 1, freq='D')[1:]\n",
        "    plt.plot(future_dates, future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (ARIMA)\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "model = train_evaluate_model(data)\n",
        "future_predictions = predict_and_compare(model, data)"
      ],
      "metadata": {
        "id": "wDAW6ucg8pVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data['Close']\n",
        "\n",
        "def train_evaluate_model(data, k=10, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)):\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    kf = KFold(n_splits=k, shuffle=False)\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_data, val_data = data.iloc[train_idx], data.iloc[val_idx]\n",
        "        model = SARIMAX(train_data, order=order, seasonal_order=seasonal_order)\n",
        "        model_fit = model.fit(disp=False)\n",
        "        val_predictions = model_fit.forecast(steps=len(val_data))\n",
        "        mse = mean_squared_error(val_data, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_data, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model_fit\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, data, prediction_steps=30):\n",
        "    test_actual = data.tail(len(data) - len(model.resid)).values\n",
        "    test_predictions = model.forecast(steps=len(test_actual))\n",
        "    future_predictions = model.forecast(steps=prediction_steps)\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(data.index[-len(test_actual):], test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(data.index[-len(test_actual):], test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    future_dates = pd.date_range(start=data.index[-1], periods=prediction_steps + 1, freq='D')[1:]\n",
        "    plt.plot(future_dates, future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (SARIMA)\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "model = train_evaluate_model(data)\n",
        "future_predictions = predict_and_compare(model, data)"
      ],
      "metadata": {
        "id": "tCY_98_j8pQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data['Close'], pd.DataFrame(index=data.index)  # فرض می‌کنیم متغیر خارجی نداریم\n",
        "\n",
        "def train_evaluate_model(data, exog, k=10, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)):\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    kf = KFold(n_splits=k, shuffle=False)\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_data, val_data = data.iloc[train_idx], data.iloc[val_idx]\n",
        "        train_exog, val_exog = exog.iloc[train_idx], exog.iloc[val_idx]\n",
        "        model = SARIMAX(train_data, exog=train_exog, order=order, seasonal_order=seasonal_order)\n",
        "        model_fit = model.fit(disp=False)\n",
        "        val_predictions = model_fit.forecast(steps=len(val_data), exog=val_exog)\n",
        "        mse = mean_squared_error(val_data, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_data, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model_fit\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, data, exog, prediction_steps=30):\n",
        "    test_actual = data.tail(len(data) - len(model.resid)).values\n",
        "    test_predictions = model.forecast(steps=len(test_actual), exog=exog.tail(len(test_actual)))\n",
        "    future_predictions = model.forecast(steps=prediction_steps)\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(data.index[-len(test_actual):], test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(data.index[-len(test_actual):], test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    future_dates = pd.date_range(start=data.index[-1], periods=prediction_steps + 1, freq='D')[1:]\n",
        "    plt.plot(future_dates, future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (SARIMAX)\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data, exog = load_data(file_path)\n",
        "model = train_evaluate_model(data, exog)\n",
        "future_predictions = predict_and_compare(model, data, exog)"
      ],
      "metadata": {
        "id": "QK7kmSxA8pLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, usecols=['Date', 'Close'])\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data['Close']\n",
        "\n",
        "def train_evaluate_model(data, k=10):\n",
        "    rmse_scores, mse_scores, mae_scores = [], [], []\n",
        "    kf = KFold(n_splits=k, shuffle=False)\n",
        "    best_model, best_mse = None, float('inf')\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_data, val_data = data.iloc[train_idx], data.iloc[val_idx]\n",
        "        model = ExponentialSmoothing(train_data, seasonal_periods=12, trend='add', seasonal='add')\n",
        "        model_fit = model.fit()\n",
        "        val_predictions = model_fit.forecast(len(val_data))\n",
        "        mse = mean_squared_error(val_data, val_predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(val_data, val_predictions)\n",
        "        mse_scores.append(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "        print(f\"Fold {fold+1} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model_fit\n",
        "    print(\"\\nFinal Cross-Validation Results:\")\n",
        "    print(f\"Average MSE: {np.mean(mse_scores):.4f}\")\n",
        "    print(f\"Average RMSE: {np.mean(rmse_scores):.4f}\")\n",
        "    print(f\"Average MAE: {np.mean(mae_scores):.4f}\")\n",
        "    return best_model\n",
        "\n",
        "def predict_and_compare(model, data, prediction_steps=30):\n",
        "    test_actual = data.tail(len(data) - len(model.resid)).values\n",
        "    test_predictions = model.forecast(len(test_actual))\n",
        "    future_predictions = model.forecast(prediction_steps)\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(data.index[-len(test_actual):], test_actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(data.index[-len(test_actual):], test_predictions, label=\"Predicted Prices (Test Data)\", color=\"green\")\n",
        "    future_dates = pd.date_range(start=data.index[-1], periods=prediction_steps + 1, freq='D')[1:]\n",
        "    plt.plot(future_dates, future_predictions, label=\"Future Predictions\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Crude Oil Price Forecast (Holt-Winters)\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "    mse_test = mean_squared_error(test_actual, test_predictions)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(test_actual, test_predictions)\n",
        "    print(\"\\nTest Data Evaluation:\")\n",
        "    print(f\"MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
        "    return future_predictions\n",
        "\n",
        "file_path = \"Crude oil.csv\"\n",
        "data = load_data(file_path)\n",
        "model = train_evaluate_model(data)\n",
        "future_predictions = predict_and_compare(model, data)"
      ],
      "metadata": {
        "id": "UeodyNqu8pHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XT4IVh9D8pCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from prophet import Prophet\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 📌 بارگذاری داده‌ها\n",
        "file_path = \"Crude oil.csv\"\n",
        "df = pd.read_csv(file_path, parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "\n",
        "# 📌 نرمال‌سازی داده‌ها\n",
        "scaler = MinMaxScaler()\n",
        "df[\"Close\"] = scaler.fit_transform(df[[\"Close\"]])\n",
        "\n",
        "# 📌 تقسیم داده‌ها به داده‌های آموزشی و تست\n",
        "train_data = df.iloc[:-365]\n",
        "test_data = df.iloc[-365:]\n",
        "\n",
        "# 📌 تعریف تابع نمایش نتایج\n",
        "def plot_results(actual, predicted, title):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(actual.index, actual, label=\"Actual Prices\", color=\"blue\")\n",
        "    plt.plot(test_data.index, predicted, label=f\"Predicted Prices ({title})\", color=\"red\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Crude Oil Price Prediction - {title}\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.show()\n",
        "\n",
        "# 📌 1️⃣ روش GRU\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim=1, hidden_dim=64, num_layers=2):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "def train_gru():\n",
        "    model = GRUModel().cuda()\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_x = torch.tensor(train_data.values[:-1].reshape(-1, 1, 1), dtype=torch.float32).cuda()\n",
        "    train_y = torch.tensor(train_data.values[1:].reshape(-1, 1), dtype=torch.float32).cuda()\n",
        "\n",
        "    dataset = TensorDataset(train_x, train_y)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        for x_batch, y_batch in loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    last_x = torch.tensor(train_data.values[-1].reshape(1, 1, 1), dtype=torch.float32).cuda()\n",
        "\n",
        "    for _ in range(365):\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(last_x).cpu().numpy()\n",
        "        predictions.append(y_pred[0, 0])\n",
        "        last_x = torch.tensor(y_pred.reshape(1, 1, 1), dtype=torch.float32).cuda()\n",
        "\n",
        "    return scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
        "\n",
        "# 📌 2️⃣ روش LSTM\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim=1, hidden_dim=64, num_layers=2):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "def train_lstm():\n",
        "    model = LSTMModel().cuda()\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_x = torch.tensor(train_data.values[:-1].reshape(-1, 1, 1), dtype=torch.float32).cuda()\n",
        "    train_y = torch.tensor(train_data.values[1:].reshape(-1, 1), dtype=torch.float32).cuda()\n",
        "\n",
        "    dataset = TensorDataset(train_x, train_y)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        for x_batch, y_batch in loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    last_x = torch.tensor(train_data.values[-1].reshape(1, 1, 1), dtype=torch.float32).cuda()\n",
        "\n",
        "    for _ in range(365):\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(last_x).cpu().numpy()\n",
        "        predictions.append(y_pred[0, 0])\n",
        "        last_x = torch.tensor(y_pred.reshape(1, 1, 1), dtype=torch.float32).cuda()\n",
        "\n",
        "    return scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
        "\n",
        "# 📌 3️⃣ روش Prophet\n",
        "def train_prophet():\n",
        "    df_prophet = df.reset_index()[[\"Date\", \"Close\"]].rename(columns={\"Date\": \"ds\", \"Close\": \"y\"})\n",
        "    model = Prophet()\n",
        "    model.fit(df_prophet)\n",
        "    future = model.make_future_dataframe(periods=365)\n",
        "    forecast = model.predict(future)\n",
        "    return forecast[\"yhat\"].values[-365:]\n",
        "\n",
        "# 📌 4️⃣ روش ARIMA\n",
        "def train_arima():\n",
        "    model = ARIMA(train_data, order=(5,1,0))\n",
        "    fitted_model = model.fit()\n",
        "    forecast = fitted_model.forecast(steps=365)\n",
        "    return forecast\n",
        "\n",
        "# 📌 5️⃣ روش SARIMA\n",
        "def train_sarima():\n",
        "    model = SARIMAX(train_data, order=(2,1,2), seasonal_order=(1,1,1,12))\n",
        "    fitted_model = model.fit()\n",
        "    forecast = fitted_model.forecast(steps=365)\n",
        "    return forecast\n",
        "\n",
        "# 📌 6️⃣ روش Holt-Winters\n",
        "def train_holt_winters():\n",
        "    model = ExponentialSmoothing(train_data, trend=\"add\", seasonal=\"add\", seasonal_periods=12)\n",
        "    fitted_model = model.fit()\n",
        "    forecast = fitted_model.forecast(steps=365)\n",
        "    return forecast\n",
        "\n"
      ],
      "metadata": {
        "id": "SuTM6zbC8o7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 اجرای مدل‌ها و نمایش نتایج\n",
        "methods = {\n",
        "    \"GRU\": train_gru,\n",
        "    \"LSTM\": train_lstm,\n",
        "    \"Prophet\": train_prophet,\n",
        "    \"ARIMA\": train_arima,\n",
        "    \"SARIMA\": train_sarima,\n",
        "    \"Holt-Winters\": train_holt_winters\n",
        "}\n",
        "\n",
        "for name, method in methods.items():\n",
        "    print(f\"\\n🔹 Running {name} Model...\")\n",
        "    predictions = method()\n",
        "    plot_results(test_data[\"Close\"], predictions, name)\n"
      ],
      "metadata": {
        "id": "1_O1TDpS8orn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}